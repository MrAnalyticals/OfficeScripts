**Using Excel Office Scripts to Simulate a Streaming Device**

![image](https://user-images.githubusercontent.com/47678539/221389935-5ce0e492-3588-4363-b298-4872221f5453.png)

In this demo video I show how to use Excel Office Scripts as a simulated streaming device integrating with Azure Data Factory , Power automate , Azure SQL db and Azure Functions to perform a t-sql generation action. 


YouTube Video URL: https://youtu.be/FybqRsqpuJA

Office Script (TypeScript): https://github.com/MrAnalyticals/OfficeScripts/blob/main/StreamDevice/OsStream1.osts

Azure Function (Python): https://github.com/MrAnalyticals/OfficeScripts/blob/main/StreamDevice/WeatherConvert%20to%20SQL.py

**Video Script**

So, here we have the Power automate flow that is simulating a streaming device sending weather data to, ultimately, an azure sql database. In this flow we have three actions, a recurrence which runs every minute. An excel office script. This generates the weather data using the random function. Then it exports the data as a json object which, in turn, gets input into a blob located on an Azure Data Lake Gen 2. The blob content is the output of the script. When this runs it replaces all of the data in that blob. So, it is only ever one record in that file. So, looking at the Data factory side of this project we can see we have four activities in the pipeline. We have one variable called SQLValue. Of data type string. The first activity is a lookup and this is connected to the temperature dot json blob file. One row is passed. In the Azure Function activity we are using a POST method. the link service is just linking to the Azure Function. The body is where the data is being transferred into the Azure Function. It is only one record. In the next activity, set variable, we can see that we are taking the output of the Function and only extracting the Response object. That response object gets transferred into the script activity. 
So, let's now have a look at the pipeline run. We can see the four activities completed successfully. If we deal with the first one. We can see the output is the contents of the blob file. We can see the value object. We have timecapture, temperature and so on. Next in the Azure function we get the data from that previous activity. The output is displayed as follows. We have the sql statement generated by the function. That is unput into the set variable. That variable is then input into the script which runs against the Azure sql database. Lets now look at the Azure function code.
So, going through the Azure function we are, first, importing three libraries as we can see here. Then we have the main function. Then we are parsing the json that was input through the body. Then, with that parsed jason value we then obtain the value object. Within the value object there are 5 items, time capture temperature and so on and each of these are assigned to a variable. Each of those variables are used to build a sql statement. The function returns that sql statement. And that finishes the Azure function.
In excel online we can see the Office Script. It is written in type script. The main function takes as a parameter the workbook and returns a string type. We are declaring five variables. We are using the random function to generate values. The time capture variable is using the date function. The next variable is Data Record which creates a jason object using those previously created variables. We then return that jason object first stringyfying it for subsequent actions in the data factory pipeline.  


![image](https://user-images.githubusercontent.com/47678539/221389950-ef446e37-2316-4c20-a88e-5a8c20dccb0f.png)
